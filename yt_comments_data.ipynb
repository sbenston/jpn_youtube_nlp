{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8880a420",
   "metadata": {},
   "source": [
    "# YouTube Comments via YouTube API\n",
    "\n",
    "This notebook utilizes Google's YouTube Data API to generate a dataset of YouTube comments from the top 15 YouTube channels by subscriber count in Japan on each channel's top 10 most viewed videos and outputs the data to a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad3758",
   "metadata": {},
   "source": [
    "To Do:\n",
    "1) ~~Check for successful request from API~~\n",
    "2) ~~Make function that can pull comments using video ID~~\n",
    "3) ~~Make function that adds relevant parts of reponse to a list of dictionaries~~\n",
    "4) Get video ids necessary\n",
    "5) ~~Iterate through ids and use created functions to generate DF~~\n",
    "6) Import DF to CSV\n",
    "\n",
    "Notes:\n",
    "* Google allows 10000 units on their quota; listing comments uses 1 unit but when testing check this\n",
    "* Listing comments has a max value of 100 - assuming each video has at least 100 comments, should result in 15,000 comments + replies\n",
    "* However might not be able to filter language here so less than that\n",
    "* While YouTube search can be used to get video_id data, quota cost is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in credentials from environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "\n",
    "# Initialize API client\n",
    "youtube = build(\n",
    "    'youtube', 'v3', developerKey=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_comments(video_id, max_results=10):\n",
    "    \n",
    "    # Make request to API and save as a variable\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet,replies',\n",
    "        maxResults=max_results,\n",
    "        order='relevance',\n",
    "        videoId=video_id\n",
    "    )\n",
    "    try:\n",
    "        response = request.execute()\n",
    "        \n",
    "        return response\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = retrieve_comments(video_id='4V0UAhe8o5c')\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae66f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response['items'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c3c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(test_response['items'][1]['replies']['comments']))\n",
    "test_response['items'][1]['replies']['comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c07c1",
   "metadata": {},
   "source": [
    "## Making the function to add to a DF\n",
    "\n",
    "1) Create empty list\n",
    "2) Iterate through response['items']\n",
    "3) Create dictionary to hold top level comment\n",
    "4) Add dictionary\n",
    "5) Check for replies - if response['items][i]['snippet']['totalReplyCount']\n",
    "6) Iterate through replies\n",
    "7) Create empty dictionary for each reply\n",
    "8) Add information from snippet\n",
    "\n",
    "When running through the response, will use a dictionary:\n",
    "{channel_id: [video_ids]}\n",
    "\n",
    "Columns desired for DataFrame:\n",
    "* channel - from dictionary used to iterate through\n",
    "* video_id - from dictionary used to iterate through\n",
    "* text\n",
    "    * top-level: response['items'][i]['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "    * reply: response['items'][i]['replies']['comments'][i]['snippet']['textOriginal']\n",
    "* date_published\n",
    "    * top-level: response['items'][i]['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "    * reply: response['items'][i]['replies']['comments'][i]['snippet']['publishedAt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68390be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(response, youtuber, video_id):\n",
    "    \n",
    "    comment_data = []\n",
    "    comment_thread = response['items']\n",
    "    \n",
    "    for item in comment_thread:\n",
    "        \n",
    "        # Grab the top-level comment first\n",
    "        comment_data.append({\n",
    "            'channel': youtuber,\n",
    "            'video_id': video_id,\n",
    "            'text': item['snippet']['topLevelComment']['snippet']['textOriginal'],\n",
    "            'date_published': item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "        })\n",
    "        \n",
    "        # Check if there are replies and get same info if there are\n",
    "        if 'replies' in item.keys():\n",
    "            \n",
    "            replies = item['replies']['comments']\n",
    "\n",
    "            for reply in replies:\n",
    "\n",
    "                comment_data.append({\n",
    "                    'channel': youtuber,\n",
    "                    'video_id': video_id,\n",
    "                    'text': reply['snippet']['textOriginal'],\n",
    "                    'date_published': reply['snippet']['publishedAt']\n",
    "                })\n",
    "        \n",
    "    return pd.DataFrame(comment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of YouTube Channels and top 10 videos\n",
    "youtubers = {'Junya Official Channel': ['4V0UAhe8o5c', '0dGh2KWJd84', 'c10am2Y1xfo', 'dYgIyCtyVXM', 'uHxJDYjzuVs',\n",
    "                                        'KnxxMhLcO2Q', 'C8GtKZDXTAk', 'YKqX_ABcI_M', '6C9P1q3oon4', 'wcCNqumbM-I'],\n",
    "             'Sagawa /さがわ': ['VVrM6JOX6gA', 'hSv5eJKniaQ', 'rSsqD1usaBM', 'zhnElWMuT0w', 'uWw8sfnZjIo',\n",
    "                               'a7ViRAx1iE0', 'FmyncJTqaQ', 'j5aR4-Bj1aE', 'nGGI_luJsO0', 'xe9XiS9AtNk']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store data\n",
    "comments_df = pd.DataFrame(columns=['channel',\n",
    "                                    'video_id',\n",
    "                                    'text',\n",
    "                                    'date_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through youtubers to add data to DF\n",
    "for youtuber, videos in youtubers.items():\n",
    "    \n",
    "    print(f'Getting comments for channel: {youtuber}')\n",
    "          \n",
    "    for video in videos:\n",
    "        \n",
    "        # Query the YouTube Data API\n",
    "        response = retrieve_comments(video)\n",
    "        sleep(3)\n",
    "        \n",
    "        # Add the data from the response to the DF\n",
    "        if response:\n",
    "            data = extract_info(response, youtuber=youtuber, video_id=video)\n",
    "            comments_df = pd.concat([comments_df, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c174da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
